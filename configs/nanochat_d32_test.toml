# Quick test of nanochat-d32 with GRPO
model_name = "models/nanochat-d32-mlx"
output_dir = "outputs/nanochat-d32-test"
run_name   = "nanochat-d32-test"

# Training (quick test)
learning_rate = 3e-6
num_epochs = 1
batch_size = 1
gradient_accumulation_steps = 1
max_train_samples = 20            # Just 20 samples for quick test
warmup_ratio = 0.1
max_grad_norm = 1.0
logging_steps = 1

# GRPO sampling
num_generations = 2               # Just 2 for speed
max_new_tokens = 64
temperature = 0.7
clip_eps = 0.2
kl_coeff = 0.01

# Evaluation
eval_steps = 5
eval_samples = 5
eval_every_updates = 5
eval_subset_size = 5
eval_max_new_tokens = 64
save_steps = 10
log_jsonl = true

# System
seed = 42
use_compile = false
quantize_for_rollouts = false    # Disable quantization - d32 is too sensitive!

