# Medium training config - Sweet spot between smoke test and production
# Uses ultra-light settings but with more training samples

model_name = "utils/mlx_model"    # ← YOUR converted model (quantized!)
output_dir = "outputs/medium-run"
run_name   = "qwen-1.5b-medium"

# training
learning_rate = 1e-6
num_epochs = 1
batch_size = 1
gradient_accumulation_steps = 1    # No accumulation (like ultra-light)
max_train_samples = 200            # ← 200 examples (between smoke_test:50 and prod:1000)
warmup_ratio = 0.1
max_grad_norm = 0.1
logging_steps = 1
save_steps = 50                    # Save every 50 steps

# sampling / rollout (minimal like ultra-light)
num_generations = 2                # Just 2 samples
max_new_tokens = 32                # Short completions
temperature = 0.7
clip_eps = 0.2
kl_coeff = 0.0

# eval & logging
eval_steps = 25
eval_samples = 10                  # Minimal eval samples
eval_every_updates = 25
eval_subset_size = 10
eval_max_new_tokens = 32           # Shorter eval
log_jsonl = true

# system
seed = 42
use_compile = false                # Disable compilation for stability


